{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b8f8c33-dcfb-4250-9566-79722317176e",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# PHASE 0a: Setup and Exploration - LLM Interpretability with SAEs\n",
    "# ============================================================================\n",
    "# This notebook explores Sparse Autoencoders for understanding LLM internals\n",
    "# Copy each section into separate Jupyter notebook cells\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: Introduction (Markdown)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "# Phase 0a: Setup and Exploration\n",
    "\n",
    "## Objectives\n",
    "1. Load a small pre-trained model (GPT-2 small) using TransformerLens\n",
    "2. Extract activations from a specific layer\n",
    "3. Explore pre-trained SAEs using SAELens\n",
    "4. Visualize how features decompose activations\n",
    "5. Find examples that maximally activate specific features\n",
    "\n",
    "## What We'll Learn\n",
    "- How to access model internals with TransformerLens\n",
    "- What activations look like (dense, polysemantic vectors)\n",
    "- How SAEs decompose activations into sparse, interpretable features\n",
    "- How to analyze what features \"mean\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a80556-34d3-4a3a-9711-9aa37cf6ac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "PyTorch version: 2.9.0+cpu\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Import Libraries\n",
    "# ============================================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TransformerLens for easy model access\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# SAELens for pre-trained SAEs  \n",
    "from sae_lens import SAE\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa33c5d-9fe2-4c89-8ded-6e03d2b29b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 small (this may take a few minutes on first run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "‚úÖ Model loaded: gpt2\n",
      "   - Layers: 12\n",
      "   - Hidden dimensions: 768\n",
      "   - Attention heads: 12\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Load GPT-2 Small with TransformerLens\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "TransformerLens wraps HuggingFace models and makes it easy to:\n",
    "- Access activations at any layer\n",
    "- Run interventions\n",
    "- Analyze model behavior\n",
    "\n",
    "We'll use GPT-2 small because:\n",
    "- It's well-studied in interpretability research\n",
    "- Small enough to run on CPU\n",
    "- Has pre-trained SAEs available\n",
    "\"\"\"\n",
    "\n",
    "print(\"Loading GPT-2 small (this may take a few minutes on first run)...\")\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    device=\"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model loaded: {model.cfg.model_name}\")\n",
    "print(f\"   - Layers: {model.cfg.n_layers}\")\n",
    "print(f\"   - Hidden dimensions: {model.cfg.d_model}\")\n",
    "print(f\"   - Attention heads: {model.cfg.n_heads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b817ff2-5196-40ee-aef4-8d24c6434485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988eb32516c54feea67b4479770c12ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: The capital of France is\n",
      "Generated: The capital of France is hosting a worldwide celebration of the 75th anniversary of\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Generate Some Text (Quick Test)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Let's verify the model works by generating some text\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"The capital of France is\"\n",
    "output = model.generate(\n",
    "    prompt,\n",
    "    max_new_tokens=10,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Generated: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbe2bb3-5bfb-4530-9970-fef82a5c5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 148\n",
      "\n",
      "Example hook points (first 10):\n",
      "  1. hook_embed\n",
      "  2. hook_pos_embed\n",
      "  3. blocks.0.ln1.hook_scale\n",
      "  4. blocks.0.ln1.hook_normalized\n",
      "  5. blocks.0.ln2.hook_scale\n",
      "  6. blocks.0.ln2.hook_normalized\n",
      "  7. blocks.0.attn.hook_k\n",
      "  8. blocks.0.attn.hook_q\n",
      "  9. blocks.0.attn.hook_v\n",
      "  10. blocks.0.attn.hook_z\n",
      "\n",
      "üí° Key hook points for interpretability:\n",
      "  - blocks.{layer}.hook_resid_pre: Residual stream before layer\n",
      "  - blocks.{layer}.hook_resid_post: Residual stream after layer\n",
      "  - blocks.{layer}.attn.hook_attn_out: Attention output\n",
      "  - blocks.{layer}.hook_mlp_out: MLP output\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Understanding Model Architecture\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Let's explore what hook points are available for extracting activations\n",
    "\"\"\"\n",
    "\n",
    "# Get all available hook points\n",
    "hook_points = [name for name, _ in model.named_parameters()]\n",
    "print(f\"Total parameters: {len(hook_points)}\")\n",
    "print(\"\\nExample hook points (first 10):\")\n",
    "for i, hook in enumerate(list(model.hook_dict.keys())[:10]):\n",
    "    print(f\"  {i+1}. {hook}\")\n",
    "\n",
    "print(\"\\nüí° Key hook points for interpretability:\")\n",
    "print(\"  - blocks.{layer}.hook_resid_pre: Residual stream before layer\")\n",
    "print(\"  - blocks.{layer}.hook_resid_post: Residual stream after layer\")\n",
    "print(\"  - blocks.{layer}.attn.hook_attn_out: Attention output\")\n",
    "print(\"  - blocks.{layer}.hook_mlp_out: MLP output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186ce13d-afd9-40bd-a4a8-819afd933cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting activations from: blocks.6.hook_mlp_out\n",
      "Analyzing 4 texts...\n",
      "\n",
      "‚úì 'The Eiffel Tower is in Paris...'\n",
      "  Activation shape: torch.Size([768])\n",
      "  Mean: 0.0000, Std: 0.8513\n",
      "\n",
      "‚úì 'Python is a programming language...'\n",
      "  Activation shape: torch.Size([768])\n",
      "  Mean: 0.0000, Std: 0.8333\n",
      "\n",
      "‚úì 'The cat sat on the mat...'\n",
      "  Activation shape: torch.Size([768])\n",
      "  Mean: -0.0000, Std: 0.8758\n",
      "\n",
      "‚úì 'Machine learning models learn patterns...'\n",
      "  Activation shape: torch.Size([768])\n",
      "  Mean: -0.0000, Std: 0.6634\n",
      "\n",
      "üìä Final activations tensor shape: torch.Size([4, 768])\n",
      "   [num_texts, d_model] = [4, 768]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Extract Activations from a Sample Text\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Let's extract activations from the MLP layer 6 (middle of the network)\n",
    "We'll use the residual stream after the MLP\n",
    "\"\"\"\n",
    "\n",
    "# Sample texts to analyze\n",
    "texts = [\n",
    "    \"The Eiffel Tower is in Paris\",\n",
    "    \"Python is a programming language\",\n",
    "    \"The cat sat on the mat\",\n",
    "    \"Machine learning models learn patterns\",\n",
    "]\n",
    "\n",
    "# Choose which layer to analyze (middle layer is often most interpretable)\n",
    "target_layer = 6\n",
    "hook_name = f\"blocks.{target_layer}.hook_mlp_out\"\n",
    "\n",
    "print(f\"Extracting activations from: {hook_name}\")\n",
    "print(f\"Analyzing {len(texts)} texts...\\n\")\n",
    "\n",
    "# Run model and cache activations\n",
    "activations_list = []\n",
    "\n",
    "for text in texts:\n",
    "    # Run model with caching\n",
    "    logits, cache = model.run_with_cache(text)\n",
    "    \n",
    "    # Extract activations from target hook\n",
    "    acts = cache[hook_name]  # Shape: [batch, seq_len, d_model]\n",
    "    \n",
    "    # Take the last token's activation (usually most informative)\n",
    "    final_activation = acts[0, -1, :]  # Shape: [d_model]\n",
    "    \n",
    "    activations_list.append(final_activation.detach().cpu())\n",
    "    \n",
    "    print(f\"‚úì '{text[:50]}...'\")\n",
    "    print(f\"  Activation shape: {final_activation.shape}\")\n",
    "    print(f\"  Mean: {final_activation.mean():.4f}, Std: {final_activation.std():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Stack all activations\n",
    "activations = torch.stack(activations_list)\n",
    "print(f\"üìä Final activations tensor shape: {activations.shape}\")\n",
    "print(f\"   [num_texts, d_model] = [{activations.shape[0]}, {activations.shape[1]}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe9d2e3-5ef5-4f2d-ae52-cbac4260a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ],
         "type": "heatmap",
         "z": {
          "bdata": "IZ+qv9ARG7+8n04/qyJBv1wcVz72eTY/zK0svji/rD4tzg4+qsu6vpMRsj74mt++U3CWPvx4rz6YXBk/sEJsPkTkL73c9bw+uo5ZPy7MhD8WpAbAqrcBP7gX9L2tUMy9AsniPqyGvr7wcow++BhXP+jYSL9h9nc/7SdHvtr2lL/2BGU/A+wCPyjVdD9OjfC9LJNXPnKScT+4Ytu9+wuxvG6kBT953MS+bnmFvo8LmL9feiS+Il8NPpbVEb+A8QC82P4fv7Qj3j4Uaz4+gBtgu5AfOT88VsQ946YuPiBB3j/Ktmu9K2eCvxDsGz8xkSW/Gam6PvCB6TuyK2q/9j/xvQLAQ76FTis/gNL9O2S6aD/CnRm+7dZQv5KSrr4BLOO/cvpmvwU8oT4AEg8/WFIBv5wpFL5CmC+/j4dLv7tbnj3NqF0/3jkgv+S06T6AbXO8HHqcv40/DL9JMAE/RvImvRAotz+GRYU/ACv3PeANTT1Yw5O+eKOwPjywD70gJVa9oF4Gv2b1eL6gKC487uh6v02hBb46QYA+OFPjPedDSD4xmIw+DazWPpxkw70EKtY+GOtmvmTWoz5ZIbU/NNcTv/Q3BL8sqVS/yLbMPyM4yz7HdIq/rinKP0wW1D6xjVq+BRXLvlUaCr8PIRi+hIsJvjvuxz7DTf4+L2eaP5i29T12W4G/XOmPvSC/Xzycj6y+doOVPvDgcT8d5jm/YJtlvw1xXL68ifC/cSLhvg5Ynr4RnQw/Lp4wvoDhJL6nY0+/2wWHv9Kdjr5dqBa/bL5JPxjqJD1eKm++D1/7PmDiRzxWDlm/jLCkPmAwyT79XD8+q3xQvqmRHL/+T4q+CcqcvmxPX74aEUK/UUrAvqMRhr8qjX8+F1C7vmxnrj2Qsoa/uv5zvtXlEz9d+lA/83C/PkDYAL4U3Oy9CV+svkCkhb78Q8Q9As72PqcZjb7k4Xc/wg0kv7QdZb6w1D2+QO80v8+gdj+xDiC+XCefP3Irgb4mGHk/DjDYPYIflT+Gp94+zWedP083IT6D+NE+3JTnvor/4L5RBPI+NssJPoguuz6a37A+PHGZPnOTmT722WM+dCRRPkBhnz7XDK8+NLFxP4b8oz6R4p++/fnPPgx3lb6w/gK95PSgPWWf2b5SCSC/5TakvoopvL/4Q269mcD4PjCXLb6G5Co+QEY2vo7xbD6ijkM/PbFUP3YzJb82v6c+iNRgv9sExL7JWG0/Yp6IPwp+zL7eSsu+01eovnYO1r3a1JY+g2oIP8TLTD+waB8/tl9ivz9TkD+/wGA9GOwIP+1cij6owLk+4xbQvqxvhj4h6BI/CEzdPgOteL9EpkK/z4AYvyuQT74gVOC+UlrjvpoUa7/wjK2+kqMnvyTGBz2iCZC/++4Hv8KEC77rKN++6+mpvrC1UD1h6Ka9G6ooP/wIaz9s1b69q7DYPkPGsbwsuAQ+Oh4fP4fO5T7zzjK/ymnMPqnmCT9c4Zm+wJQ+P6XoOj6CzG6/2GTNPic1L78ALDs+yLkWv6aoSz6Q72K+BnwGvv+P0r7hb0I//PMIP9cL7D4bUHw+OEzGO4jU1rz+JYg+eJZ0P7B9zD5+dHC+MqdgPjRwbL6OZpQ/YJb7vqAsgj8YOau+T+51P/nlED9TkIk++BVHvo7ZY7+szIU9TCquPjB/x75AlPS8lB42P6mimT9QAnq+htIGvrnZzb7UQn8/TrEAP1spEL9qhX+/FtUyPgYWx750FiO95J9Jv9ARoL92q+K+0vc9vqOo3j4rHBq/SNT5PfIGXr4duCi/KHkoPgDYObucmg2+xqMrvxxHbL9c0zi/JYDLvhEPOD9xFIm/SHt3Pzq9yz5OpMm+aFLevcBmjTsom28/4Exvvt6eKL8QrHw+OK0xv5WqUb9UmbU+ONCmPnjU3T36CxU/ntrwvrEK2D4jLZe/sMhZv959sT5c/yq/DYwJvzTbMD5cB9g+tNbJvo6Irb4Pn5S/rsHlvVNjQ8D71a6/c0nJvr9aET/8f1O//nDSPmZwqT7lpQu/JshcP72iG75mOzo/fQFrPiV5Ir+CZUU+dNH6PoIyD78smWS+k9KEv1bvuL4gSXC970NIP3Amx76Gs6y+riVyvsCZrL0kA1a+KUBcPor/l7/inzo/aU7Gvzh8/b2Q6sI9Hv2+PhTCw776JY2/6ABkvgijJD+vXa2/lmv6vVTbvD743XM/YGfoPUTBcz9NNEC/pCjnvo+Ih77GMxC/iU2zv0BxCb7CVDa/T8jCPlsZjL9eddo+pGXGvYsportgXRO/YvzhPi5ZBj/4eg09e3YevkDnSr8088k8e7q7vsLOJz8eoKo/wGw2vcZu/71WYxc/dc2Sv0R//j6WzBm/ACLAvZ45tj4U+1++bk8HQdDMXL0JAgI/n6ievp/GFj8QMc4+rIlLv/AQxr/DlWE+dWrSvq+93D729A+/wDjxPcAoGL02v9k+oiSaPvhpSL9K65u+M3LOPiIDdz9+i8I9rnJ5vnafKz9+cUe9YGCOPtfAGr6jwuC+AbokP5ss4D4IMcK/KmQDv2A+cr2eoKW/EJ4+vQM+X0HDEzo+UvGKv7YPrT7MT7u9rYN2vox6J7/E7EA/08nEPt7Myz7RwU0/QxTXPtCiZ7/XJiY+ZKepvs6Itj8kG8S/XAyOPWgsGT2icMw+uCKcP1iubT3ddVu/MWFYvx/VXz0IFuC9e0puP/oo675H4XU/MHfxvFJUST9FyK4+JJZQvpi0OD8+Hly+03wPvyaRa7+ss6i9mukVvyI8rT4W+ky/fjfYPSRxsj8st4u9LIe2Puq8QL4GJ8C+OVW7vkbA8D231eA+vRMIP6C45L/Q2oI85W5tvxqgUj+LomK/fvRpvh8tGr4zDCS+Obczv0tOLT7EKlQ+bDA4vbAsnz7xqtw+YKWMvZOFEj9QRyU8Ot0qvlpYaT5t+sa+AYCWPZDhnj4xmug+0HC+PZeyPj8xn3k+hKS1vuK6or/tcIo+Pt85v3dWlD/sqIq+yLuuPNgHD7wfGC4/dDETPvTvPr57o5i+WoAbPy9UCj5AoEk9odbyvoKidz6qpiE/CrwlP9bHLD9q/lQ/FN31PhmEjr+MIam9rC92PvKXXj7OrLc9UKc/viklp76SUC6/cHUGv8MYCL9WkYu+Uv6nv37UCD+DzLe+4/SMvwAQULrAG5e+GR5Gvhkdg7/xeQI+CHn4vy50/T6BmfC+2sl9vtX/gb44u/M+yK2BP8v4Gj+sDOm9Qj/vPiDwOj7QWdW+1nzDPqbTWD9cPUI9MVG+PfyTwL6l/+8+7ph7PcPJpj95Ali/YgZ7v76VJb/7OPY+gSAuvzcWsz7xOzu/bA16vcxyBb+6cP2+jWn4vriHBj/LpS0/QiNPvkQU5T4q0uK+RXhCPmNtmL4bsVi/By0bP2ZaTj6Wkn0/RMNGPZq6Hz8AXqG7p/Sivnu+ur6p8zE+fmNvP+acNb+wd9o+Sy+fPktKED8v3W6//1nZvig8kz0BzGO+5Id4P6yVrj1QnrE+yDFtPSnRYL7sAXO+rENZPziJJz4zWyA+EKbTPuYTlD0WVOI/pnubPZpp/T75SGK/YQcSP3G00L4fuqk+AisQv1J0tL8kI7q9Tt2LvS1+Kz7g77E9DmmjPRKjIj6gR/0+QIxlPW7fqL6o06U9/BwxP+pAtb7ccDw+njZHv8yHBj5sZr293LfzPuhWGj/xuAS/EkysPkrhUT/Aot69MAnLvFxI5T4g/Ze78p+Vvn+l/D60tLs+xDp0v1dAFD9uZE4/KO2rvbA9wL3McTi/WflIvjVFp75LiuK/O8InPp28Cj9opp08nGxIv3M79b400QE9wdiCvowSHD5qh5a+0OqzPLPpkz5Fuja/2VKCvimSrr2i2JC//SwAvzbvYT/I/N+9Z0k2PyK7Qj9y/8G+sIxrvyD63j6v+O2+IatFv2sAej62Ue++Lu37PrUQhz4QShi/moQ3v1R/Lb4b440+RvIAP+dEtL1Gpbq/47WgPrOpOz9qIRE/IlAwvz8zF78Agy2/04c/PpvfiT6jpgG/Cu4Iv5j9U75wj4C7hqW2PquF776yOZs/hc0dPkIjiL4Kz48+",
          "dtype": "f4",
          "shape": "1, 768"
         },
         "zmid": 0
        }
       ],
       "layout": {
        "height": 200,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Raw Activation for: 'The Eiffel Tower is in Paris'"
        },
        "xaxis": {
         "title": {
          "text": "Dimension"
         }
        },
        "yaxis": {
         "showticklabels": false,
         "title": {
          "text": ""
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Activation Statistics:\n",
      "Mean activation: 0.0000\n",
      "Std activation: 0.8513\n",
      "Max activation: 13.9526\n",
      "Min activation: -3.0529\n",
      "Sparsity (% zeros): 0.00%\n",
      "Sparsity (% near-zero, <0.01): 1.69%\n",
      "\n",
      "üí° Notice: The activation is DENSE (very few zeros)\n",
      "   This makes it hard to interpret - which dimensions matter?\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Visualize Raw Activations\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Let's visualize what these raw activations look like\n",
    "They should be dense (most values non-zero) and hard to interpret\n",
    "\"\"\"\n",
    "\n",
    "# Create a heatmap of the first text's activation\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=activations[0].unsqueeze(0).numpy(),\n",
    "    colorscale='RdBu',\n",
    "    zmid=0,\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=f\"Raw Activation for: '{texts[0]}'\",\n",
    "    xaxis_title=\"Dimension\",\n",
    "    yaxis_title=\"\",\n",
    "    height=200,\n",
    "    yaxis=dict(showticklabels=False)\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\nüìà Activation Statistics:\")\n",
    "print(f\"Mean activation: {activations[0].mean():.4f}\")\n",
    "print(f\"Std activation: {activations[0].std():.4f}\")\n",
    "print(f\"Max activation: {activations[0].max():.4f}\")\n",
    "print(f\"Min activation: {activations[0].min():.4f}\")\n",
    "print(f\"Sparsity (% zeros): {(activations[0] == 0).float().mean() * 100:.2f}%\")\n",
    "print(f\"Sparsity (% near-zero, <0.01): {(activations[0].abs() < 0.01).float().mean() * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nüí° Notice: The activation is DENSE (very few zeros)\")\n",
    "print(\"   This makes it hard to interpret - which dimensions matter?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1c0e4da-4792-44b0-b4ee-85fc2c634c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load pre-trained SAE...\n",
      "Target hook: blocks.6.hook_mlp_out\n",
      "\n",
      "Loading SAE from local cache...\n",
      "‚úÖ SAE loaded successfully!\n",
      "   - SAE input dim: 768\n",
      "   - SAE hidden dim: 24576\n",
      "   - Expansion factor: 32.0x\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Load pre-trained SAE\n",
    "# ============================================================================\n",
    "print(\"Attempting to load pre-trained SAE...\")\n",
    "print(f\"Target hook: {hook_name}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    from sae_lens import SAE\n",
    "    import os\n",
    "    \n",
    "    print(\"Loading SAE from local cache...\")\n",
    "\n",
    "    # Use the correct API - load_from_disk\n",
    "    cache_path = os.path.expanduser(\"~/.cache/sae_lens/blocks.6.hook_resid_pre\")\n",
    "    \n",
    "    # Load from the cache we just downloaded\n",
    "    sae = SAE.load_from_disk(\n",
    "        path=cache_path,\n",
    "        device=\"cpu\"\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ SAE loaded successfully!\")\n",
    "    print(f\"   - SAE input dim: {sae.cfg.d_in}\")\n",
    "    print(f\"   - SAE hidden dim: {sae.cfg.d_sae}\")\n",
    "    print(f\"   - Expansion factor: {sae.cfg.d_sae / sae.cfg.d_in:.1f}x\")\n",
    "    # Try to get sparsity coefficient if it exists\n",
    "    if hasattr(sae.cfg, 'l1_coeff'):\n",
    "        print(f\"   - L1 coefficient: {sae.cfg.l1_coeff}\")\n",
    "    elif hasattr(sae.cfg, 'sparsity_coefficient'):\n",
    "        print(f\"   - Sparsity coefficient: {sae.cfg.sparsity_coefficient}\")\n",
    "    \n",
    "    sae_loaded = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Could not load pre-trained SAE: {e}\")\n",
    "    print()\n",
    "    print(\"For now, we'll continue with simulated examples.\")\n",
    "    print(\"Later, we'll train our own custom SAE!\")\n",
    "    \n",
    "    sae_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022c5f0c-cc2e-40d8-8790-817a6530d35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéì Understanding SAE Transformation:\n",
      "\n",
      "Original activation: [768 dimensions, mostly non-zero]\n",
      "         ‚Üì\n",
      "    SAE Encoder\n",
      "         ‚Üì\n",
      "SAE features: [4096 features, only ~10-20 non-zero]\n",
      "         ‚Üì\n",
      "    SAE Decoder\n",
      "         ‚Üì\n",
      "Reconstructed: [768 dimensions, close to original]\n",
      "\n",
      "Example of sparse features (simulated):\n",
      "\n",
      "üìä Simulated SAE Features:\n",
      "   Total features: 4096\n",
      "   Active features (L0): 10\n",
      "   Sparsity: 99.76%\n",
      "\n",
      "Active features and their strengths:\n",
      "   Feature #347: 0.90 (e.g., 'concept about X')\n",
      "   Feature #1052: 0.70 (e.g., 'concept about X')\n",
      "   Feature #2891: 0.60 (e.g., 'concept about X')\n",
      "   Feature #3201: 0.50 (e.g., 'concept about X')\n",
      "   Feature #156: 0.40 (e.g., 'concept about X')\n",
      "   Feature #2003: 0.40 (e.g., 'concept about X')\n",
      "   Feature #987: 0.30 (e.g., 'concept about X')\n",
      "   Feature #3456: 0.30 (e.g., 'concept about X')\n",
      "   Feature #1234: 0.20 (e.g., 'concept about X')\n",
      "   Feature #567: 0.20 (e.g., 'concept about X')\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Simple SAE Demonstration (Conceptual)\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Since we may not have a pre-trained SAE readily available, let's demonstrate\n",
    "the CONCEPT of what an SAE does with a simple example\n",
    "\"\"\"\n",
    "\n",
    "print(\"üéì Understanding SAE Transformation:\")\n",
    "print()\n",
    "print(\"Original activation: [768 dimensions, mostly non-zero]\")\n",
    "print(\"         ‚Üì\")\n",
    "print(\"    SAE Encoder\")\n",
    "print(\"         ‚Üì\")\n",
    "print(\"SAE features: [4096 features, only ~10-20 non-zero]\")\n",
    "print(\"         ‚Üì\")\n",
    "print(\"    SAE Decoder\")\n",
    "print(\"         ‚Üì\")\n",
    "print(\"Reconstructed: [768 dimensions, close to original]\")\n",
    "print()\n",
    "\n",
    "# Simulate what SAE features might look like (conceptual)\n",
    "print(\"Example of sparse features (simulated):\")\n",
    "print()\n",
    "\n",
    "# Create a simulated sparse representation\n",
    "d_sae = 4096  # SAE typically expands to more dimensions\n",
    "simulated_features = torch.zeros(d_sae)\n",
    "\n",
    "# Only activate a few features (this is the KEY property of SAEs)\n",
    "active_features = [347, 1052, 2891, 3201, 156, 2003, 987, 3456, 1234, 567]\n",
    "feature_strengths = [0.9, 0.7, 0.6, 0.5, 0.4, 0.4, 0.3, 0.3, 0.2, 0.2]\n",
    "\n",
    "for feat_idx, strength in zip(active_features, feature_strengths):\n",
    "    simulated_features[feat_idx] = strength\n",
    "\n",
    "# Show statistics\n",
    "sparsity = (simulated_features == 0).float().mean() * 100\n",
    "l0_norm = (simulated_features != 0).sum().item()\n",
    "\n",
    "print(f\"üìä Simulated SAE Features:\")\n",
    "print(f\"   Total features: {d_sae}\")\n",
    "print(f\"   Active features (L0): {l0_norm}\")\n",
    "print(f\"   Sparsity: {sparsity:.2f}%\")\n",
    "print()\n",
    "print(f\"Active features and their strengths:\")\n",
    "for feat_idx, strength in zip(active_features, feature_strengths):\n",
    "    print(f\"   Feature #{feat_idx}: {strength:.2f} (e.g., 'concept about X')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752f9357-f04e-465a-9b53-c1d886aea098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Applying Real SAE to Our Activations\n",
      "============================================================\n",
      "\n",
      "Analyzing: 'The Eiffel Tower is in Paris'\n",
      "Original activation shape: torch.Size([1, 768])\n",
      "SAE features shape: torch.Size([1, 24576])\n",
      "Total features: 24576\n",
      "\n",
      "üìä Sparsity Analysis:\n",
      "   Active features (L0): 3108\n",
      "   Sparsity: 87.35%\n",
      "\n",
      "üîù Top 10 Active Features:\n",
      "   1. Feature #10399: 13.368\n",
      "   2. Feature #13648: 12.817\n",
      "   3. Feature #9815: 11.650\n",
      "   4. Feature #12103: 11.056\n",
      "   5. Feature #5527: 10.990\n",
      "   6. Feature #14940: 8.592\n",
      "   7. Feature #11446: 8.094\n",
      "   8. Feature #20661: 8.000\n",
      "   9. Feature #15124: 7.842\n",
      "   10. Feature #18146: 7.774\n",
      "\n",
      "üí° Each of these features represents a single interpretable concept!\n",
      "   (In a fully analyzed SAE, we'd know what each feature means)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: Transforming activations using a pretrained SAE\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Now let's use the REAL SAE we loaded to transform our actual activations!\n",
    "\"\"\"\n",
    "\n",
    "if sae_loaded:\n",
    "    print(\"üî¨ Applying Real SAE to Our Activations\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Take the first text's activation\n",
    "    text_idx = 0\n",
    "    text = texts[text_idx]\n",
    "    activation = activations[text_idx].unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    print(f\"\\nAnalyzing: '{text}'\")\n",
    "    print(f\"Original activation shape: {activation.shape}\")\n",
    "    \n",
    "    # Run through SAE encoder to get sparse features\n",
    "    with torch.no_grad():\n",
    "        feature_acts = sae.encode(activation)\n",
    "    \n",
    "    print(f\"SAE features shape: {feature_acts.shape}\")\n",
    "    print(f\"Total features: {feature_acts.shape[1]}\")\n",
    "    \n",
    "    # Calculate sparsity\n",
    "    num_active = (feature_acts[0] > 0).sum().item()\n",
    "    sparsity_pct = 100 * (1 - num_active / feature_acts.shape[1])\n",
    "    \n",
    "    print(f\"\\nüìä Sparsity Analysis:\")\n",
    "    print(f\"   Active features (L0): {num_active}\")\n",
    "    print(f\"   Sparsity: {sparsity_pct:.2f}%\")\n",
    "    \n",
    "    # Get top 10 active features\n",
    "    top_vals, top_indices = feature_acts[0].topk(10)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 Active Features:\")\n",
    "    for i, (idx, val) in enumerate(zip(top_indices, top_vals)):\n",
    "        print(f\"   {i+1}. Feature #{idx.item()}: {val.item():.3f}\")\n",
    "    \n",
    "    print(f\"\\nüí° Each of these features represents a single interpretable concept!\")\n",
    "    print(f\"   (In a fully analyzed SAE, we'd know what each feature means)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SAE not loaded, skipping real analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "332b4f31-aec3-400c-ae4f-6445901713ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Investigating Feature #10399\n",
      "============================================================\n",
      "\n",
      "Testing which texts activate Feature #10399:\n",
      "\n",
      "[ 15.01] The Eiffel Tower is beautiful\n",
      "[ 12.14] Paris is the capital of France\n",
      "[ 13.20] London has Big Ben\n",
      "[ 11.65] I love French cuisine\n",
      "[ 13.42] The tower was built in 1889\n",
      "[ 11.33] Tokyo is in Japan\n",
      "\n",
      "üí° Based on these activations, what do you think Feature #10399 represents?\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: Testing the Activation of A Feature When Exposed to Text Examples\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Let's investigate what Feature #10399 might represent\n",
    "\"\"\"\n",
    "\n",
    "if sae_loaded:\n",
    "    print(\"üîç Investigating Feature #10399\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test this feature on different texts\n",
    "    test_texts = [\n",
    "        \"The Eiffel Tower is beautiful\",\n",
    "        \"Paris is the capital of France\",\n",
    "        \"London has Big Ben\",\n",
    "        \"I love French cuisine\",\n",
    "        \"The tower was built in 1889\",\n",
    "        \"Tokyo is in Japan\",\n",
    "    ]\n",
    "    \n",
    "    feature_idx = 10399\n",
    "    \n",
    "    print(f\"\\nTesting which texts activate Feature #{feature_idx}:\\n\")\n",
    "    \n",
    "    for text in test_texts:\n",
    "        # Get activations for this text\n",
    "        logits, cache = model.run_with_cache(text)\n",
    "        acts = cache[hook_name][0, -1, :].unsqueeze(0)\n",
    "        \n",
    "        # Run through SAE\n",
    "        with torch.no_grad():\n",
    "            features = sae.encode(acts)\n",
    "            feature_val = features[0, feature_idx].item()\n",
    "        \n",
    "        print(f\"[{feature_val:6.2f}] {text}\")\n",
    "    \n",
    "    print(f\"\\nüí° Based on these activations, what do you think Feature #{feature_idx} represents?\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SAE not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf7142bc-d447-464a-a529-cb0cce7aab71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Neuronpedia Links for Top Features:\n",
      "============================================================\n",
      "\n",
      "Feature #10399: https://neuronpedia.org/gpt2-small/6-res-jb/10399\n",
      "Feature #13648: https://neuronpedia.org/gpt2-small/6-res-jb/13648\n",
      "Feature #9815: https://neuronpedia.org/gpt2-small/6-res-jb/9815\n",
      "Feature #12103: https://neuronpedia.org/gpt2-small/6-res-jb/12103\n",
      "Feature #5527: https://neuronpedia.org/gpt2-small/6-res-jb/5527\n",
      "\n",
      "üí° Click these links to see:\n",
      "   - What texts maximally activate each feature\n",
      "   - Human interpretations of what they represent\n",
      "   - Activation patterns and examples\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: Using Neuonpedia to Determine the Meaning of A Feature\n",
    "# ============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Generate Neuronpedia links for our top features\n",
    "\"\"\"\n",
    "\n",
    "if sae_loaded:\n",
    "    print(\"üîó Neuronpedia Links for Top Features:\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    # Top features we found\n",
    "    top_features = [10399, 13648, 9815, 12103, 5527]\n",
    "    \n",
    "    # Neuronpedia URL pattern\n",
    "    base_url = \"https://neuronpedia.org/gpt2-small/6-res-jb\"\n",
    "    \n",
    "    for feat in top_features:\n",
    "        url = f\"{base_url}/{feat}\"\n",
    "        print(f\"Feature #{feat}: {url}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"üí° Click these links to see:\")\n",
    "    print(\"   - What texts maximally activate each feature\")\n",
    "    print(\"   - Human interpretations of what they represent\")\n",
    "    print(\"   - Activation patterns and examples\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SAE not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898d2ac1-db48-4858-8f08-3e187e59a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dense vs Sparse Comparison\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "lightblue"
         },
         "name": "Original (Dense)",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": {
          "bdata": "IZ+qv9ARG7+8n04/qyJBv1wcVz72eTY/zK0svji/rD4tzg4+qsu6vpMRsj74mt++U3CWPvx4rz6YXBk/sEJsPkTkL73c9bw+uo5ZPy7MhD8WpAbAqrcBP7gX9L2tUMy9AsniPqyGvr7wcow++BhXP+jYSL9h9nc/7SdHvtr2lL/2BGU/A+wCPyjVdD9OjfC9LJNXPnKScT+4Ytu9+wuxvG6kBT953MS+bnmFvo8LmL9feiS+Il8NPpbVEb+A8QC82P4fv7Qj3j4Uaz4+gBtgu5AfOT88VsQ946YuPiBB3j/Ktmu9K2eCvxDsGz8xkSW/Gam6PvCB6TuyK2q/9j/xvQLAQ76FTis/gNL9O2S6aD/CnRm+7dZQv5KSrr4BLOO/cvpmvwU8oT4AEg8/WFIBv5wpFL5CmC+/j4dLv7tbnj3NqF0/3jkgv+S06T6AbXO8HHqcv40/DL9JMAE/RvImvRAotz+GRYU/ACv3PeANTT1Yw5O+eKOwPjywD70gJVa9oF4Gv2b1eL6gKC487uh6vw==",
          "dtype": "f4"
         }
        },
        {
         "marker": {
          "color": "coral"
         },
         "name": "SAE Features (Sparse)",
         "type": "bar",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC+Xss+AAAAAAAAAAAAAAAACtNGPgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHU9XT8AAAAAAAAAAAAAAADkgpw906bjPwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAitI+QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGgyhkAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAggr9PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWdqePgAAAAAAAAAAAAAAAPIqK0AecUQ/5OwgQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABbTeQ/AAAAAA==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "barmode": "overlay",
        "height": 400,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Dense vs Sparse Representations (First 100 dimensions)"
        },
        "xaxis": {
         "title": {
          "text": "Dimension Index"
         }
        },
        "yaxis": {
         "title": {
          "text": "Activation Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí° Key Insight:\n",
      "   - Original: Most dimensions have some activation (hard to interpret)\n",
      "   - SAE: Only a few features are active (each represents one concept)\n",
      "\n",
      "======================================================================\n",
      "üìà Full Statistical Analysis\n",
      "======================================================================\n",
      "\n",
      "üîµ Original (Dense) Activation:\n",
      "   Total dimensions: 768\n",
      "   Exactly zero: 0 (0.0%)\n",
      "   Near-zero (<0.01): 13 (1.7%)\n",
      "   Significant: 755 (98.3%)\n",
      "   Layout: [0 -------- 768]\n",
      "           ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  ‚Üê Almost all dimensions active\n",
      "\n",
      "üü† SAE (Sparse) Features:\n",
      "   Total dimensions: 24576\n",
      "   Active (>0): 3108 (12.65%)\n",
      "   Zero: 21468 (87.35%)\n",
      "\n",
      "   Distribution of 3108 active features across 24576 dimensions:\n",
      "   [    0-  792]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (111)\n",
      "   [  792- 1585]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (97)\n",
      "   [ 1585- 2378]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (94)\n",
      "   [ 2378- 3171]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (108)\n",
      "   [ 3171- 3963]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (94)\n",
      "   [ 3963- 4756]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (83)\n",
      "   [ 4756- 5549]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (125)\n",
      "   [ 5549- 6342]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (104)\n",
      "   [ 6342- 7134]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (87)\n",
      "   [ 7134- 7927]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (89)\n",
      "   [ 7927- 8720]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (92)\n",
      "   [ 8720- 9513]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (116)\n",
      "   [ 9513-10306]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (100)\n",
      "   [10306-11098]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (107)\n",
      "   [11098-11891]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (108)\n",
      "   [11891-12684]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (95)\n",
      "   [12684-13477]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (109)\n",
      "   [13477-14269]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (85)\n",
      "   [14269-15062]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (103)\n",
      "   [15062-15855]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (96)\n",
      "   [15855-16648]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (85)\n",
      "   [16648-17441]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (88)\n",
      "   [17441-18233]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (96)\n",
      "   [18233-19026]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (120)\n",
      "   [19026-19819]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (115)\n",
      "   [19819-20612]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (100)\n",
      "   [20612-21404]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (87)\n",
      "   [21404-22197]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (100)\n",
      "   [22197-22990]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (108)\n",
      "   [22990-23783]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (85)\n",
      "   [23783-24576]: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (121)\n",
      "\n",
      "üí° Key Insight:\n",
      "   Original: 755/768 dimensions significantly active\n",
      "            ‚Üí DENSE: Hard to know which dimensions represent which concepts\n",
      "   SAE:      3108/24576 features active\n",
      "            ‚Üí SPARSE: Each active feature = one interpretable concept!\n",
      "            ‚Üí 87.4% of features are zero (high sparsity)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: Visualize Sparse vs Dense Representations\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Visualize the difference between dense and sparse representations\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìä Dense vs Sparse Comparison\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================================================\n",
    "# PART 13a: Side-by-side bar chart (first 100 dimensions)\n",
    "# ============================================================================\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Plot 1: Dense original activation (first 100 dims for visibility)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list(range(100)),\n",
    "    y=activations[0][:100].numpy(),\n",
    "    name='Original (Dense)',\n",
    "    marker_color='lightblue'\n",
    "))\n",
    "\n",
    "# Plot 2: Sparse SAE features (first 100 for comparison)\n",
    "if sae_loaded:\n",
    "    with torch.no_grad():\n",
    "        sae_features = sae.encode(activations[0].unsqueeze(0))\n",
    "    sparse_display = sae_features[0][:100].numpy()\n",
    "else:\n",
    "    sparse_display = simulated_features[:100].numpy()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=list(range(100)),\n",
    "    y=sparse_display,\n",
    "    name='SAE Features (Sparse)',\n",
    "    marker_color='coral'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dense vs Sparse Representations (First 100 dimensions)\",\n",
    "    xaxis_title=\"Dimension Index\",\n",
    "    yaxis_title=\"Activation Value\",\n",
    "    barmode='overlay',\n",
    "    height=400\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   - Original: Most dimensions have some activation (hard to interpret)\")\n",
    "print(\"   - SAE: Only a few features are active (each represents one concept)\")\n",
    "\n",
    "# ============================================================================\n",
    "# PART 13b: Full statistical comparison and distribution\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìà Full Statistical Analysis\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Original activation stats\n",
    "orig_nonzero = (activations[0] != 0).sum().item()\n",
    "orig_near_zero = (activations[0].abs() < 0.01).sum().item()\n",
    "orig_total = activations[0].numel()\n",
    "\n",
    "print(f\"\\nüîµ Original (Dense) Activation:\")\n",
    "print(f\"   Total dimensions: {orig_total}\")\n",
    "print(f\"   Exactly zero: {orig_total - orig_nonzero} ({100*(orig_total-orig_nonzero)/orig_total:.1f}%)\")\n",
    "print(f\"   Near-zero (<0.01): {orig_near_zero} ({100*orig_near_zero/orig_total:.1f}%)\")\n",
    "print(f\"   Significant: {orig_total - orig_near_zero} ({100*(orig_total-orig_near_zero)/orig_total:.1f}%)\")\n",
    "print(f\"   Layout: [0 -------- {orig_total}]\")\n",
    "print(f\"           \" + \"‚ñà\" * 60 + \"  ‚Üê Almost all dimensions active\")\n",
    "\n",
    "if sae_loaded:\n",
    "    # SAE feature stats\n",
    "    sae_nonzero = (sae_features[0] > 0).sum().item()\n",
    "    sae_total = sae_features[0].numel()\n",
    "    \n",
    "    print(f\"\\nüü† SAE (Sparse) Features:\")\n",
    "    print(f\"   Total dimensions: {sae_total}\")\n",
    "    print(f\"   Active (>0): {sae_nonzero} ({100*sae_nonzero/sae_total:.2f}%)\")\n",
    "    print(f\"   Zero: {sae_total - sae_nonzero} ({100*(sae_total-sae_nonzero)/sae_total:.2f}%)\")\n",
    "    \n",
    "    # Show where the active features are located\n",
    "    active_indices = torch.where(sae_features[0] > 0)[0]\n",
    "    \n",
    "    print(f\"\\n   Distribution of {sae_nonzero} active features across {sae_total} dimensions:\")\n",
    "    \n",
    "    # Dynamic number of bins (aim for ~50-200 features per bin)\n",
    "    target_features_per_bin = 100\n",
    "    num_bins = max(20, min(50, sae_nonzero // target_features_per_bin))\n",
    "    \n",
    "    hist, bin_edges = torch.histogram(active_indices.float(), bins=num_bins, range=(0, sae_total))\n",
    "    \n",
    "    max_count = hist.max().item()\n",
    "    for i in range(num_bins):\n",
    "        count = hist[i].item()\n",
    "        bar_length = int(50 * count / max_count) if max_count > 0 else 0\n",
    "        bin_start = int(bin_edges[i])\n",
    "        bin_end = int(bin_edges[i+1])\n",
    "        print(f\"   [{bin_start:5d}-{bin_end:5d}]: {'‚ñà' * bar_length} ({int(count)})\")\n",
    "    \n",
    "    print(f\"\\nüí° Key Insight:\")\n",
    "    print(f\"   Original: {orig_total - orig_near_zero}/{orig_total} dimensions significantly active\")\n",
    "    print(f\"            ‚Üí DENSE: Hard to know which dimensions represent which concepts\")\n",
    "    print(f\"   SAE:      {sae_nonzero}/{sae_total} features active\")\n",
    "    print(f\"            ‚Üí SPARSE: Each active feature = one interpretable concept!\")\n",
    "    print(f\"            ‚Üí {100*(sae_total-sae_nonzero)/sae_total:.1f}% of features are zero (high sparsity)\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  SAE not loaded, using simulated features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc81d71-8215-49f6-a579-0f94f4bf54f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Example Feature Interpretation Process:\n",
      "\n",
      "Feature #1052 (simulated)\n",
      "==================================================\n",
      "\n",
      "Top activating texts (these would be found by searching a dataset):\n",
      "  [0.95] Paris is the capital of France\n",
      "  [0.89] I visited Paris last summer\n",
      "  [0.87] The Paris metro is efficient\n",
      "  [0.82] Parisian cafes are charming\n",
      "\n",
      "‚û°Ô∏è  Interpretation: This feature represents 'Paris' or Paris-related concepts\n",
      "\n",
      "This is how researchers discover what features mean:\n",
      "1. Find texts that maximally activate each feature\n",
      "2. Look for patterns in those texts\n",
      "3. Hypothesize what concept the feature represents\n",
      "4. Test the hypothesis on new examples\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: Feature Interpretation Example\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "This is what feature interpretation looks like in practice:\n",
    "We find what text makes each feature activate strongly\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Example Feature Interpretation Process:\")\n",
    "print()\n",
    "print(\"Feature #1052 (simulated)\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"Top activating texts (these would be found by searching a dataset):\")\n",
    "example_texts = [\n",
    "    (\"Paris is the capital of France\", 0.95),\n",
    "    (\"I visited Paris last summer\", 0.89),\n",
    "    (\"The Paris metro is efficient\", 0.87),\n",
    "    (\"Parisian cafes are charming\", 0.82),\n",
    "]\n",
    "\n",
    "for text, activation in example_texts:\n",
    "    print(f\"  [{activation:.2f}] {text}\")\n",
    "\n",
    "print()\n",
    "print(\"‚û°Ô∏è  Interpretation: This feature represents 'Paris' or Paris-related concepts\")\n",
    "print()\n",
    "print(\"This is how researchers discover what features mean:\")\n",
    "print(\"1. Find texts that maximally activate each feature\")\n",
    "print(\"2. Look for patterns in those texts\")\n",
    "print(\"3. Hypothesize what concept the feature represents\")\n",
    "print(\"4. Test the hypothesis on new examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a6a649e-4b22-4262-8311-c5e4f6fe2756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìù PHASE 0a SUMMARY\n",
      "======================================================================\n",
      "\n",
      "‚úÖ What we learned:\n",
      "   1. How to load models with TransformerLens\n",
      "   2. How to extract activations from specific layers\n",
      "   3. What dense, polysemantic activations look like\n",
      "   4. The concept of SAE decomposition into sparse features\n",
      "   5. How feature interpretation works\n",
      "\n",
      "üéØ Key Insight:\n",
      "   SAEs transform dense, uninterpretable activations\n",
      "   into sparse, monosemantic features where each feature\n",
      "   represents a single, interpretable concept\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 15: Next Steps & Summary\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Summary and Next Steps\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìù PHASE 0a SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"‚úÖ What we learned:\")\n",
    "print(\"   1. How to load models with TransformerLens\")\n",
    "print(\"   2. How to extract activations from specific layers\")\n",
    "print(\"   3. What dense, polysemantic activations look like\")\n",
    "print(\"   4. The concept of SAE decomposition into sparse features\")\n",
    "print(\"   5. How feature interpretation works\")\n",
    "print()\n",
    "print(\"üéØ Key Insight:\")\n",
    "print(\"   SAEs transform dense, uninterpretable activations\")\n",
    "print(\"   into sparse, monosemantic features where each feature\")\n",
    "print(\"   represents a single, interpretable concept\")\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84877893-6dd1-4ab3-aeef-370c70f6d2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Saved activations to: ../data/phase0a_activations.pt\n",
      "\n",
      "These can be loaded in future notebooks with:\n",
      "   data = torch.load('../data/phase0a_activations.pt')\n",
      "   activations = data['activations']\n",
      "   texts = data['texts']\n",
      "‚úÖ File exists at: /home/thebuleganteng/01_Repos/06_personal_work/interpretability-prototyping/data/phase0a_activations.pt\n",
      "   File size: 0.01 MB\n",
      "\n",
      "üì¶ Contents:\n",
      "   - Activations shape: torch.Size([4, 768])\n",
      "   - Number of texts: 4\n",
      "   - Layer: 6\n",
      "   - Hook: blocks.6.hook_mlp_out\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 16: Save Progress\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Let's save the activations we collected for future use\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Save activations\n",
    "torch.save({\n",
    "    'activations': activations,\n",
    "    'texts': texts,\n",
    "    'layer': target_layer,\n",
    "    'hook_name': hook_name,\n",
    "    'model_name': 'gpt2-small'\n",
    "}, '../data/phase0a_activations.pt')\n",
    "\n",
    "print(\"üíæ Saved activations to: ../data/phase0a_activations.pt\")\n",
    "print()\n",
    "print(\"These can be loaded in future notebooks with:\")\n",
    "print(\"   data = torch.load('../data/phase0a_activations.pt')\")\n",
    "print(\"   activations = data['activations']\")\n",
    "print(\"   texts = data['texts']\")\n",
    "\n",
    "\n",
    "# Check if file exists\n",
    "file_path = '../data/phase0a_activations.pt'\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"‚úÖ File exists at: {os.path.abspath(file_path)}\")\n",
    "    \n",
    "    # Check file size\n",
    "    size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "    print(f\"   File size: {size_mb:.2f} MB\")\n",
    "    \n",
    "    # Load and verify contents\n",
    "    data = torch.load(file_path)\n",
    "    print(f\"\\nüì¶ Contents:\")\n",
    "    print(f\"   - Activations shape: {data['activations'].shape}\")\n",
    "    print(f\"   - Number of texts: {len(data['texts'])}\")\n",
    "    print(f\"   - Layer: {data['layer']}\")\n",
    "    print(f\"   - Hook: {data['hook_name']}\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found at: {os.path.abspath(file_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed756f7-724e-43ef-af1d-4a2978348374",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 17: Resources & Documentation\n",
    "# ============================================================================\n",
    "\"\"\"\n",
    "Useful resources for continued learning\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìö LEARNING RESOURCES\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"üîó Key Papers:\")\n",
    "print(\"   ‚Ä¢ Scaling Monosemanticity (Anthropic 2024)\")\n",
    "print(\"     https://transformer-circuits.pub/2024/scaling-monosemanticity/\")\n",
    "print()\n",
    "print(\"   ‚Ä¢ Towards Monosemanticity (Anthropic 2023)\")\n",
    "print(\"     https://transformer-circuits.pub/2023/monosemantic-features/\")\n",
    "print()\n",
    "print(\"   ‚Ä¢ Toy Models of Superposition (Anthropic 2022)\")\n",
    "print(\"     https://transformer-circuits.pub/2022/toy_model/\")\n",
    "print()\n",
    "print(\"üõ†Ô∏è  Tools:\")\n",
    "print(\"   ‚Ä¢ TransformerLens Docs: https://transformerlensorg.github.io/TransformerLens/\")\n",
    "print(\"   ‚Ä¢ SAELens GitHub: https://github.com/jbloomAus/SAELens\")\n",
    "print(\"   ‚Ä¢ Neuronpedia: https://neuronpedia.org/\")\n",
    "print()\n",
    "print(\"üë• Community:\")\n",
    "print(\"   ‚Ä¢ Neel Nanda's MI Guide: https://www.neelnanda.io/mechanistic-interpretability\")\n",
    "print(\"   ‚Ä¢ ARENA Interpretability: https://arena3-chapter1-transformer-interp.streamlit.app/\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n‚ú® Great work! You've completed Phase 0a!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9682cb-de63-40c5-a6bd-f5fc121c5b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
